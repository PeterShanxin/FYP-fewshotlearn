# High-throughput, multi-GPU (A40 48GB) configuration

# Number of GPUs to use when available (embedding step is multi-GPU aware).
# Training/eval of ProtoNet remain single-GPU as they operate on episodic batches
# with support/query coupling that doesn't trivially shard.
gpus: 2

embedding:
  # Larger ESM2 backbone for better representations
  # Options: esm2_t33_650M_UR50D, esm2_t36_3B_UR50D (3B likely too large for 48GB)
  model: esm2_t33_650M_UR50D

# Device selection: "auto" → cuda if available else cpu
device: auto

# Optional: load HPC environment modules before running
# Adjust names/versions to your cluster (e.g., MMseqs2/14, cd-hit/4.8.1)
modules:
  - MMseqs2
  - CD-HIT

# Episode settings (few-shot task shape)
episode:
  M: 10              # ways
  K_train: 5         # shots for training episodes
  K_eval: [1, 5]     # shots evaluated on test episodes
  Q: 10              # queries per class

# Episode counts (raise for tighter confidence intervals)
episodes:
  train: 10000       # 5k–20k recommended; start with 10k
  val: 2000          # increase validation episodes
  eval: 5000         # meta-test episodes for tight CIs

# Embedding runtime knobs (optimize throughput)
batch_size_embed: 1536   # 2x A40 with FP16+DP; dynamic_batch adapts on OOM
max_seq_len: 1022        # full ESM2 context window
fp16: true               # use FP16 inference on GPU
dynamic_batch: true      # auto-reduce batch on OOM
progress: true
verbose: false

# ProtoNet head
projection_dim: 256
temperature: 10.0

# Training knobs
fp16_train: false            # AMP for ProtoNet head (gains minimal; keep FP32)
eval_every: 1000             # validate every 1k episodes (10 checks across 10k)
episodes_per_val_check: 200  # 200-episode validation slices (faster interim CIs)

# Multi-label and hierarchy
multi_label: true             # allow sequences with multiple ECs; uses BCE loss on queries
hierarchy_levels: 2           # add auxiliary losses on EC levels (1..N), 0=off
hierarchy_weight: 0.2         # total weight for auxiliary hierarchical losses

# Identity-aware sampling (requires clusters_tsv)
identity_disjoint: true       # keep support/query disjoint by cluster within class when true

# Identity clustering (pipeline-generated)
cluster_identity: 0.5         # sequence identity threshold for clustering
cluster_coverage: 0.5         # minimum coverage fraction for MMseqs2 clustering

# Identity benchmark (multi-threshold CV)
id_thresholds: [10, 30, 50, 70, 100]
folds: 5
identity_definition: tool_default      # global_pairwise | local_pairwise | tool_default
clustering_method: existing_id_cluster_module
stratify_by: EC_top

# Data filtering and splits
min_sequences_per_class_for_train: 40
random_seed: 42
allow_multi_ec: true

# Fetch
force_fetch: false

# Paths
paths:
  data_root: data/uniprot_ec
  joined_tsv: data/uniprot_ec/swissprot_ec_joined.tsv
  embeddings: data/emb/embeddings.npz
  splits_dir: data/splits
  outputs: results
  # Optional clustering map for identity-aware sampling: accession\tcluster_id
  clusters_tsv: data/identity/clusters.tsv
