# Smoke-test configuration: tiny, fast, CPU-friendly

# Explicitly disable GPU usage to keep smoke runs on CPU
gpus: 0

embedding:
  model: esm2_t12_35M_UR50D

# Force CPU for widest compatibility in CI/smoke
device: cpu

# Keep episodes extremely small for speed
episode:
  M: 1              # ways (1-way episodes keep test minimal)
  K_train: 1        # 1-shot training
  K_eval: [1]       # evaluate only 1-shot
  Q: 1              # 1 query per class

episodes:
  train: 5          # a handful of train episodes
  val: 2            # tiny validation
  eval: 5           # tiny meta-test

# Embedding runtime knobs
batch_size_embed: 1
max_seq_len: 80     # truncate to speed up ESM
truncate_long_sequences: true
progress: false
verbose: true
dynamic_batch: false

# ProtoNet head kept small
projection_dim: 64
temperature: 10.0

# With replacement sampling allows tiny per-class counts
min_sequences_per_class_for_train: 2
random_seed: 123

# Turn on optional features for smoke; clusters are generated automatically
multi_label: true
hierarchy_levels: 1
hierarchy_weight: 0.2
identity_disjoint: true
allow_multi_ec: true

# Clustering defaults (auto)
cluster_identity: 0.5
cluster_coverage: 0.5

# Identity benchmark defaults for smoke (fast)
# Required: list of one or more thresholds (percent or fractions)
id_thresholds: [10, 50, 100]
folds: 3
identity_definition: tool_default
clustering_method: existing_id_cluster_module
stratify_by: EC_top

# Fetch fresh data in smoke as well (small run)
force_fetch: false

# Limit the size of splits for smoke (applied in prepare_split)
limit_classes: 5           # keep only top-N EC classes by count
limit_per_class: 3         # and at most this many accessions per class

# Use the main fetched dataset; keep smoke outputs separate
paths:
  data_root: data/uniprot_ec
  joined_tsv: data/uniprot_ec/swissprot_ec_joined.tsv
  embeddings: data/emb/embeddings_smoke
  splits_dir: data/splits_smoke
  outputs: results/smoke
  clusters_tsv: data/identity/clusters_smoke.tsv
