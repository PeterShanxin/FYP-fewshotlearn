# Smoke-test configuration: tiny, fast, CPU-friendly

# Explicitly disable GPU usage to keep smoke runs on CPU
gpus: 0

embedding:
  model: esm2_t12_35M_UR50D

# Force CPU for widest compatibility in CI/smoke
device: cpu

# Keep episodes extremely small for speed
episode:
  M_train: 1
  K_train: 1
  Q_train: 1
  M_val: 1
  K_val: 1
  Q_val: 1

episodes:
  train: 5          # a handful of train episodes
  val: 2            # tiny validation
  eval: 5           # tiny meta-test

# Embedding runtime knobs
batch_size_embed: 1
max_seq_len: 80     # truncate to speed up ESM
truncate_long_sequences: true
progress: false
verbose: true
dynamic_batch: false

# ProtoNet head kept small
projection_dim: 64
temperature: 10.0

# With replacement sampling allows tiny per-class counts
min_sequences_per_class_for_train: 1
random_seed: 123

# Turn on optional features for smoke; clusters are generated automatically
multi_label: true
hierarchy_levels: 1
hierarchy_weight: 0.2
allow_multi_ec: true

cascade:
  enabled: false

tau_multi: 0.60

detector:
  enabled: false
  loss_weight: 0.10
  thresh: 0.50
  hidden_dim: 32

sampler:
  identity_disjoint: true
  with_replacement_fallback: true
  fallback_scope: all
  rare_class_boost: inverse_log_freq

eval:
  mode: global_support
  shortlist_topN: 0
  temperature: 0.07
  tau_multi: 0.35
  per_ec_thresholds_path: null
  subprototypes_per_ec: 1
  prototypes_path: artifacts/prototypes_smoke.npz
  calibration_path: artifacts/calibration_smoke.json
  split: val

# Clustering defaults (auto)
cluster_identity: 0.5
cluster_coverage: 0.5

# Identity benchmark defaults for smoke (fast)
# Required: list of one or more thresholds (percent or fractions)
id_thresholds: [10, 50, 100]
folds: 3
identity_definition: tool_default
clustering_method: existing_id_cluster_module
stratify_by: EC_top
identity_benchmark:
  episodic: true
  global_support: true

# Fetch fresh data in smoke as well (small run)
force_fetch: false

# Limit the size of splits for smoke (applied in prepare_split)
limit_classes: 5           # keep only top-N EC classes by count
limit_per_class: 3         # and at most this many accessions per class

# Use the main fetched dataset; keep smoke outputs separate
paths:
  data_root: data/uniprot_ec
  joined_tsv: data/uniprot_ec/swissprot_ec_joined.tsv
  embeddings: data/emb/embeddings_smoke
  splits_dir: data/splits_smoke
  outputs: results/smoke
  runs: runs/smoke
  clusters_tsv: data/identity/clusters_smoke.tsv
